#!/usr/bin/env python3
"""
INVESTIGAÃ‡ÃƒO PROFUNDA DO FLUXO DE DADOS
========================================

Este arquivo investiga NO MÃNIMO DETALHE:
1. O que load_news.py estÃ¡ salvando em texto_bruto
2. Se process_articles.py estÃ¡ alterando texto_bruto
3. Onde exatamente os dados estÃ£o sendo perdidos

NÃƒO ALTERA NENHUM CÃ“DIGO - APENAS INVESTIGA!
"""

import sys
import os
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Any, List, Optional
import json

# Adiciona o diretÃ³rio backend ao path
backend_dir = Path(__file__).parent / "backend"
sys.path.insert(0, str(backend_dir))

# Imports do backend
try:
    from dotenv import load_dotenv
    from sqlalchemy.orm import Session
    from sqlalchemy import func, text
    
    from backend.database import SessionLocal, ArtigoBruto, ClusterEvento
    from backend.crud import (
        get_artigos_by_cluster, get_cluster_by_id, get_artigos_pendentes
    )
    
    print("âœ… MÃ³dulos do backend importados com sucesso!")
except ImportError as e:
    print(f"âŒ ERRO ao importar mÃ³dulos: {e}")
    sys.exit(1)

# Carrega variÃ¡veis de ambiente
env_file = backend_dir / ".env"
if env_file.exists():
    load_dotenv(env_file)
    print(f"âœ… Arquivo .env carregado: {env_file}")

def print_header(title: str, char: str = "=", width: int = 80):
    """Imprime cabeÃ§alho formatado"""
    print(f"\n{char * width}")
    print(f"{title:^{width}}")
    print(f"{char * width}")

def print_section(title: str, char: str = "-", width: int = 60):
    """Imprime seÃ§Ã£o formatada"""
    print(f"\n{char * width}")
    print(f"{title:^{width}}")
    print(f"{char * width}")

def print_data(title: str, data: Any, max_length: int = 200):
    """Imprime dados formatados com limite de caracteres"""
    if isinstance(data, str):
        if len(data) > max_length:
            data_display = data[:max_length] + f"... [TRUNCADO - {len(data)} chars]"
        else:
            data_display = data
    else:
        data_display = str(data)
    
    print(f"ğŸ“‹ {title}:")
    print(f"   {data_display}")

def investigar_artigo_especifico(artigo_id: int):
    """Investiga um artigo especÃ­fico em TODOS os detalhes"""
    print_header(f"ğŸ”¬ INVESTIGAÃ‡ÃƒO PROFUNDA DO ARTIGO {artigo_id}")
    
    try:
        db = SessionLocal()
        
        # Busca o artigo
        artigo = db.query(ArtigoBruto).filter(ArtigoBruto.id == artigo_id).first()
        if not artigo:
            print(f"âŒ Artigo {artigo_id} nÃ£o encontrado")
            return
        
        print_section("ğŸ“Š DADOS BÃSICOS DO ARTIGO")
        print_data("ID", artigo.id)
        print_data("Hash Ãšnico", artigo.hash_unico)
        print_data("Fonte de Coleta", artigo.fonte_coleta)
        print_data("Status", artigo.status)
        print_data("Criado em", artigo.created_at)
        print_data("Processado em", artigo.processed_at)
        print_data("Cluster ID", artigo.cluster_id)
        
        # ANÃLISE DETALHADA DO TEXTO BRUTO
        print_section("ğŸ“– ANÃLISE DETALHADA DO TEXTO BRUTO")
        if artigo.texto_bruto:
            texto_bruto = artigo.texto_bruto
            print(f"ï¿½ï¿½ Tamanho: {len(texto_bruto)} caracteres")
            print(f"ğŸ“ Primeiros 200 chars: {texto_bruto[:200]}")
            print(f"ï¿½ï¿½ Ãšltimos 200 chars: {texto_bruto[-200:]}")
            
            # AnÃ¡lise de conteÃºdo
            if len(texto_bruto) < 500:
                print("âš ï¸ TEXTO MUITO CURTO - provavelmente resumo, nÃ£o texto original")
            elif len(texto_bruto) < 2000:
                print("âš ï¸ TEXTO CURTO - pode ser resumo ou texto truncado")
            else:
                print("âœ… TEXTO LONGO - pode ser texto original")
            
            # Verifica se parece resumo
            palavras_resumo = ['notÃ­cia', 'matÃ©ria', 'artigo', 'peÃ§a', 'apresenta', 'incluindo']
            if any(palavra in texto_bruto.lower() for palavra in palavras_resumo):
                print("ğŸš¨ PARECE SER RESUMO (contÃ©m palavras tÃ­picas de resumo)")
            else:
                print("âœ… PARECE SER TEXTO ORIGINAL (nÃ£o contÃ©m palavras de resumo)")
                
        else:
            print("âŒ TEXTO BRUTO: NÃƒO DEFINIDO")
        
        # ANÃLISE DETALHADA DO TEXTO PROCESSADO
        print_section("ğŸ“ ANÃLISE DETALHADA DO TEXTO PROCESSADO")
        if artigo.texto_processado:
            texto_processado = artigo.texto_processado
            print(f"ï¿½ï¿½ Tamanho: {len(texto_processado)} caracteres")
            print(f"ğŸ“ Primeiros 200 chars: {texto_processado[:200]}")
            print(f"ï¿½ï¿½ Ãšltimos 200 chars: {texto_processado[-200:]}")
            
            # AnÃ¡lise de conteÃºdo
            if len(texto_processado) < 500:
                print("âœ… TEXTO CURTO - provavelmente resumo (correto)")
            else:
                print("âš ï¸ TEXTO LONGO - pode ser texto original (incorreto)")
                
        else:
            print("âŒ TEXTO PROCESSADO: NÃƒO DEFINIDO")
        
        # COMPARAÃ‡ÃƒO DETALHADA
        print_section("ğŸ” COMPARAÃ‡ÃƒO DETALHADA")
        if artigo.texto_bruto and artigo.texto_processado:
            if artigo.texto_bruto == artigo.texto_processado:
                print("ğŸš¨ PROBLEMA CRÃTICO: texto_bruto e texto_processado sÃ£o IDÃŠNTICOS!")
                print("   Isso significa que:")
                print("   - OU ambos contÃªm resumos (texto_bruto deveria ter texto original)")
                print("   - OU ambos contÃªm texto original (texto_processado deveria ter resumo)")
            else:
                print("âœ… OK: texto_bruto e texto_processado sÃ£o diferentes")
                
                # Verifica qual Ã© qual
                if len(artigo.texto_bruto) > len(artigo.texto_processado):
                    print("   âœ… texto_bruto > texto_processado (correto)")
                else:
                    print("   âš ï¸ texto_processado > texto_bruto (pode estar incorreto)")
                    
                # Verifica similaridade
                from difflib import SequenceMatcher
                similaridade = SequenceMatcher(None, artigo.texto_bruto, artigo.texto_processado).ratio()
                print(f"   ï¿½ï¿½ Similaridade entre os textos: {similaridade:.2%}")
                
                if similaridade > 0.8:
                    print("   âš ï¸ ATENÃ‡ÃƒO: Textos muito similares (pode haver problema)")
                elif similaridade < 0.3:
                    print("   âœ… OK: Textos bem diferentes (correto)")
                else:
                    print("   âš ï¸ ATENÃ‡ÃƒO: Textos moderadamente similares")
        
        # ANÃLISE DOS METADADOS
        print_section("ğŸ”§ ANÃLISE DETALHADA DOS METADADOS")
        if artigo.metadados:
            metadados = artigo.metadados
            print("ğŸ“‹ Metadados disponÃ­veis:")
            for chave, valor in metadados.items():
                if isinstance(valor, str) and len(valor) > 100:
                    print(f"   {chave}: {valor[:100]}... [TRUNCADO - {len(valor)} chars]")
                else:
                    print(f"   {chave}: {valor}")
            
            # Verifica campos importantes
            campos_importantes = ['texto_completo', 'arquivo_origem', 'tipo_arquivo', 'data_processamento']
            for campo in campos_importantes:
                if campo in metadados:
                    print(f"âœ… Campo '{campo}' encontrado: {metadados[campo]}")
                else:
                    print(f"âŒ Campo '{campo}' NÃƒO encontrado")
                    
            # Verifica se tem texto completo nos metadados
            if 'texto_completo' in metadados:
                texto_completo_meta = metadados['texto_completo']
                print(f"\nï¿½ï¿½ TEXTO COMPLETO dos metadados:")
                print(f"   ï¿½ï¿½ Tamanho: {len(texto_completo_meta)} caracteres")
                print(f"   ğŸ“ Primeiros 200 chars: {texto_completo_meta[:200]}")
                
                # Compara com texto_bruto
                if artigo.texto_bruto:
                    if texto_completo_meta == artigo.texto_bruto:
                        print("   âœ… texto_completo dos metadados = texto_bruto (correto)")
                    else:
                        print("   ğŸš¨ PROBLEMA: texto_completo dos metadados â‰  texto_bruto")
                        print("   Isso significa que o texto_bruto foi alterado apÃ³s a ingestÃ£o!")
                        
                        # Verifica qual Ã© mais longo
                        if len(texto_completo_meta) > len(artigo.texto_bruto):
                            print("   ï¿½ï¿½ texto_completo dos metadados > texto_bruto")
                            print("   ï¿½ï¿½ PROBLEMA: texto_bruto foi TRUNCADO ou RESUMIDO!")
                        else:
                            print("   ï¿½ï¿½ texto_completo dos metadados < texto_bruto")
                            print("   âš ï¸ ATENÃ‡ÃƒO: texto_bruto foi EXPANDIDO (pode estar incorreto)")
            else:
                print("âŒ Campo 'texto_completo' NÃƒO encontrado nos metadados")
                
        else:
            print("âŒ METADADOS: NÃƒO DEFINIDO")
        
        # ANÃLISE DO FLUXO
        print_section("ğŸ”„ ANÃLISE DO FLUXO DE PROCESSAMENTO")
        
        # Verifica se foi processado
        if artigo.status == 'processado':
            print("ï¿½ï¿½ Status: processado")
            print("   âœ… Artigo foi processado pelo process_articles.py")
            
            # Verifica se tem cluster
            if artigo.cluster_id:
                print(f"   ğŸ”— Associado ao cluster {artigo.cluster_id}")
                
                # Busca dados do cluster
                cluster = get_cluster_by_id(db, artigo.cluster_id)
                if cluster:
                    print(f"   ï¿½ï¿½ TÃ­tulo do cluster: {cluster.titulo_cluster}")
                    if cluster.resumo_cluster:
                        print(f"   ï¿½ï¿½ Resumo do cluster: {cluster.resumo_cluster[:200]}...")
                    else:
                        print("   âŒ Cluster sem resumo")
                else:
                    print("   âŒ Cluster nÃ£o encontrado")
            else:
                print("   âŒ NÃƒO associado a cluster")
        else:
            print(f"ğŸ“Š Status: {artigo.status}")
            print("   âš ï¸ Artigo NÃƒO foi processado ainda")
        
        db.close()
        return True
        
    except Exception as e:
        print(f"âŒ ERRO ao investigar artigo: {e}")
        import traceback
        traceback.print_exc()
        return False

def investigar_artigos_por_fonte():
    """Investiga artigos por fonte de coleta para entender padrÃµes"""
    print_header("ï¿½ï¿½ INVESTIGAÃ‡ÃƒO POR FONTE DE COLETA")
    
    try:
        db = SessionLocal()
        
        # Busca fontes de coleta Ãºnicas
        query = text("""
            SELECT 
                fonte_coleta,
                COUNT(*) as total,
                COUNT(CASE WHEN texto_bruto IS NOT NULL THEN 1 END) as com_texto_bruto,
                COUNT(CASE WHEN texto_processado IS NOT NULL THEN 1 END) as com_texto_processado,
                AVG(LENGTH(texto_bruto)) as avg_tamanho_bruto,
                AVG(LENGTH(texto_processado)) as avg_tamanho_processado,
                MIN(created_at) as primeiro,
                MAX(created_at) as ultimo
            FROM artigos_brutos
            GROUP BY fonte_coleta
            ORDER BY total DESC
            LIMIT 10
        """)
        
        fontes = db.execute(query).fetchall()
        
        print("ğŸ“Š AnÃ¡lise por fonte de coleta:")
        for fonte in fontes:
            print(f"\nğŸ“° FONTE: {fonte.fonte_coleta}")
            print(f"   ğŸ“Š Total: {fonte.total}")
            print(f"   ï¿½ï¿½ Com texto_bruto: {fonte.com_texto_bruto}")
            print(f"   ğŸ“ Com texto_processado: {fonte.com_texto_processado}")
            print(f"   ğŸ“ Tamanho mÃ©dio texto_bruto: {fonte.avg_tamanho_bruto:.0f} chars")
            print(f"   ğŸ“ Tamanho mÃ©dio texto_processado: {fonte.avg_tamanho_processado:.0f} chars")
            print(f"   ğŸ“… PerÃ­odo: {fonte.primeiro} atÃ© {fonte.ultimo}")
            
            # AnÃ¡lise de padrÃ£o
            if fonte.avg_tamanho_bruto < 1000:
                print("   âš ï¸ ATENÃ‡ÃƒO: texto_bruto muito curto (pode ser resumo)")
            elif fonte.avg_tamanho_bruto > 5000:
                print("   âœ… OK: texto_bruto longo (pode ser texto original)")
            else:
                print("   âš ï¸ ATENÃ‡ÃƒO: texto_bruto tamanho mÃ©dio (pode estar truncado)")
                
            if fonte.avg_tamanho_processado > 1000:
                print("   âš ï¸ ATENÃ‡ÃƒO: texto_processado muito longo (pode ser texto original)")
            else:
                print("   âœ… OK: texto_processado curto (pode ser resumo)")
        
        db.close()
        
    except Exception as e:
        print(f"âŒ ERRO ao investigar por fonte: {e}")

def investigar_artigos_por_tipo():
    """Investiga artigos por tipo de arquivo (PDF vs JSON)"""
    print_header("ï¿½ï¿½ INVESTIGAÃ‡ÃƒO POR TIPO DE ARQUIVO")
    
    try:
        db = SessionLocal()
        
        # Busca artigos com metadados que indiquem tipo
        query = text("""
            SELECT 
                metadados->>'tipo_arquivo' as tipo,
                COUNT(*) as total,
                AVG(LENGTH(texto_bruto)) as avg_tamanho_bruto,
                AVG(LENGTH(texto_processado)) as avg_tamanho_processado,
                COUNT(CASE WHEN LENGTH(texto_bruto) < 1000 THEN 1 END) as texto_bruto_curto,
                COUNT(CASE WHEN LENGTH(texto_bruto) > 5000 THEN 1 END) as texto_bruto_longo
            FROM artigos_brutos
            WHERE metadados IS NOT NULL
            GROUP BY metadados->>'tipo_arquivo'
            ORDER BY total DESC
        """)
        
        tipos = db.execute(query).fetchall()
        
        print("ğŸ“Š AnÃ¡lise por tipo de arquivo:")
        for tipo in tipos:
            if not tipo.tipo:
                continue
                
            print(f"\nğŸ“ TIPO: {tipo.tipo}")
            print(f"   ï¿½ï¿½ Total: {tipo.total}")
            print(f"   ğŸ“ Tamanho mÃ©dio texto_bruto: {tipo.avg_tamanho_bruto:.0f} chars")
            print(f"   ğŸ“ Tamanho mÃ©dio texto_processado: {tipo.avg_tamanho_processado:.0f} chars")
            print(f"   âš ï¸ texto_bruto curto (<1000): {tipo.texto_bruto_curto}")
            print(f"   âœ… texto_bruto longo (>5000): {tipo.texto_bruto_longo}")
            
            # AnÃ¡lise especÃ­fica por tipo
            if tipo.tipo == 'pdf':
                if tipo.avg_tamanho_bruto < 2000:
                    print("   ï¿½ï¿½ PROBLEMA: PDFs com texto_bruto muito curto!")
                    print("   ğŸ’¡ Isso sugere que o OCR/LLM estÃ¡ resumindo em vez de extrair texto completo")
                else:
                    print("   âœ… OK: PDFs com texto_bruto longo (texto completo extraÃ­do)")
                    
            elif tipo.tipo == 'json':
                if tipo.avg_tamanho_bruto > 2000:
                    print("   âœ… OK: JSONs com texto_bruto longo (texto completo preservado)")
                else:
                    print("   âš ï¸ ATENÃ‡ÃƒO: JSONs com texto_bruto curto (pode estar sendo processado)")
        
        db.close()
        
    except Exception as e:
        print(f"âŒ ERRO ao investigar por tipo: {e}")

def investigar_artigos_recentes():
    """Investiga artigos criados recentemente para entender o padrÃ£o atual"""
    print_header("ğŸ• INVESTIGAÃ‡ÃƒO DE ARTIGOS RECENTES")
    
    try:
        db = SessionLocal()
        
        # Busca artigos das Ãºltimas 24h
        query = text("""
            SELECT 
                id,
                fonte_coleta,
                metadados->>'tipo_arquivo' as tipo,
                LENGTH(texto_bruto) as tamanho_bruto,
                LENGTH(texto_processado) as tamanho_processado,
                status,
                created_at
            FROM artigos_brutos
            WHERE created_at >= NOW() - INTERVAL '24 hours'
            ORDER BY created_at DESC
            LIMIT 20
        """)
        
        artigos_recentes = db.execute(query).fetchall()
        
        print(f"ğŸ“Š Artigos criados nas Ãºltimas 24h: {len(artigos_recentes)}")
        
        for artigo in artigos_recentes:
            print(f"\nï¿½ï¿½ Artigo {artigo.id} ({artigo.created_at.strftime('%H:%M')})")
            print(f"   ğŸ“° Fonte: {artigo.fonte_coleta}")
            print(f"   ï¿½ï¿½ Tipo: {artigo.tipo or 'N/A'}")
            print(f"   ğŸ“ Tamanho texto_bruto: {artigo.tamanho_bruto} chars")
            print(f"   ğŸ“ Tamanho texto_processado: {artigo.tamanho_processado} chars")
            print(f"   ğŸ“Š Status: {artigo.status}")
            
            # AnÃ¡lise rÃ¡pida
            if artigo.tamanho_bruto < 1000:
                print("   âš ï¸ texto_bruto muito curto")
            elif artigo.tamanho_bruto > 5000:
                print("   âœ… texto_bruto longo")
            else:
                print("   âš ï¸ texto_bruto tamanho mÃ©dio")
                
            if artigo.tamanho_processado and artigo.tamanho_processado > 1000:
                print("   âš ï¸ texto_processado muito longo")
            elif artigo.tamanho_processado:
                print("   âœ… texto_processado adequado")
            else:
                print("   âŒ texto_processado nÃ£o definido")
        
        db.close()
        
    except Exception as e:
        print(f"âŒ ERRO ao investigar artigos recentes: {e}")

def main():
    """FunÃ§Ã£o principal da investigaÃ§Ã£o"""
    print_header("ğŸ”¬ INVESTIGAÃ‡ÃƒO PROFUNDA DO FLUXO DE DADOS", "=", 80)
    print(f"ğŸ“… Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. Investigar artigo especÃ­fico (do diagnÃ³stico anterior)
    artigo_id = 7108  # Artigo que mostrou problema no diagnÃ³stico
    print(f"\nï¿½ï¿½ INVESTIGANDO ARTIGO ESPECÃFICO: {artigo_id}")
    investigar_artigo_especifico(artigo_id)
    
    # 2. Investigar por fonte de coleta
    print_header("ï¿½ï¿½ INVESTIGAÃ‡ÃƒO POR FONTE")
    investigar_artigos_por_fonte()
    
    # 3. Investigar por tipo de arquivo
    print_header("ï¿½ï¿½ INVESTIGAÃ‡ÃƒO POR TIPO")
    investigar_artigos_por_tipo()
    
    # 4. Investigar artigos recentes
    print_header("ğŸ• INVESTIGAÃ‡ÃƒO RECENTE")
    investigar_artigos_recentes()
    
    # 5. RESUMO FINAL
    print_header("ï¿½ï¿½ RESUMO DA INVESTIGAÃ‡ÃƒO", "=", 80)
    print("âœ… INVESTIGAÃ‡ÃƒO CONCLUÃDA!")
    print("\nğŸ” PRÃ“XIMOS PASSOS:")
    print("1. Analise os resultados acima")
    print("2. Identifique padrÃµes nos problemas")
    print("3. Determine se o problema estÃ¡ em:")
    print("   - load_news.py (ingestÃ£o)")
    print("   - process_articles.py (processamento)")
    print("   - Ambos")
    print("4. Planeje correÃ§Ãµes especÃ­ficas")
    
    print("\nğŸš¨ PROBLEMAS ESPERADOS:")
    print("- PDFs sendo processados por LLM na ingestÃ£o")
    print("- texto_bruto sendo sobrescrito no processamento")
    print("- Falta de preservaÃ§Ã£o do texto original")
    print("- Metadados nÃ£o sendo usados corretamente")

if __name__ == "__main__":
    main()