#!/usr/bin/env python3
"""
INVESTIGA√á√ÉO PROFUNDA DO FLUXO DE DADOS
========================================

Este arquivo investiga NO M√çNIMO DETALHE:
1. O que load_news.py est√° salvando em texto_bruto
2. Se process_articles.py est√° alterando texto_bruto
3. Onde exatamente os dados est√£o sendo perdidos

N√ÉO ALTERA NENHUM C√ìDIGO - APENAS INVESTIGA!
"""

import sys
import os
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Any, List, Optional
import json

# Adiciona o diret√≥rio backend ao path
backend_dir = Path(__file__).parent / "backend"
sys.path.insert(0, str(backend_dir))

# Imports do backend
try:
    from dotenv import load_dotenv
    from sqlalchemy.orm import Session
    from sqlalchemy import func, text
    
    from backend.database import SessionLocal, ArtigoBruto, ClusterEvento
    from backend.crud import (
        get_artigos_by_cluster, get_cluster_by_id, get_artigos_pendentes
    )
    
    print("‚úÖ M√≥dulos do backend importados com sucesso!")
except ImportError as e:
    print(f"‚ùå ERRO ao importar m√≥dulos: {e}")
    sys.exit(1)

# Carrega vari√°veis de ambiente
env_file = backend_dir / ".env"
if env_file.exists():
    load_dotenv(env_file)
    print(f"‚úÖ Arquivo .env carregado: {env_file}")

def print_header(title: str, char: str = "=", width: int = 80):
    """Imprime cabe√ßalho formatado"""
    print(f"\n{char * width}")
    print(f"{title:^{width}}")
    print(f"{char * width}")

def print_section(title: str, char: str = "-", width: int = 60):
    """Imprime se√ß√£o formatada"""
    print(f"\n{char * width}")
    print(f"{title:^{width}}")
    print(f"{char * width}")

def print_data(title: str, data: Any, max_length: int = 200):
    """Imprime dados formatados com limite de caracteres"""
    if isinstance(data, str):
        if len(data) > max_length:
            data_display = data[:max_length] + f"... [TRUNCADO - {len(data)} chars]"
        else:
            data_display = data
    else:
        data_display = str(data)
    
    print(f"üìã {title}:")
    print(f"   {data_display}")

def investigar_artigo_especifico(artigo_id: int):
    """Investiga um artigo espec√≠fico em TODOS os detalhes"""
    print_header(f"üî¨ INVESTIGA√á√ÉO PROFUNDA DO ARTIGO {artigo_id}")
    
    try:
        db = SessionLocal()
        
        # Busca o artigo
        artigo = db.query(ArtigoBruto).filter(ArtigoBruto.id == artigo_id).first()
        if not artigo:
            print(f"‚ùå Artigo {artigo_id} n√£o encontrado")
            return
        
        print_section("üìä DADOS B√ÅSICOS DO ARTIGO")
        print_data("ID", artigo.id)
        print_data("Hash √önico", artigo.hash_unico)
        print_data("Fonte de Coleta", artigo.fonte_coleta)
        print_data("Status", artigo.status)
        print_data("Criado em", artigo.created_at)
        print_data("Processado em", artigo.processed_at)
        print_data("Cluster ID", artigo.cluster_id)
        
        # AN√ÅLISE DETALHADA DO TEXTO BRUTO
        print_section("üìñ AN√ÅLISE DETALHADA DO TEXTO BRUTO")
        if artigo.texto_bruto:
            texto_bruto = artigo.texto_bruto
            print(f"ÔøΩÔøΩ Tamanho: {len(texto_bruto)} caracteres")
            print(f"üìù Primeiros 200 chars: {texto_bruto[:200]}")
            print(f"ÔøΩÔøΩ √öltimos 200 chars: {texto_bruto[-200:]}")
            
            # An√°lise de conte√∫do
            if len(texto_bruto) < 500:
                print("‚ö†Ô∏è TEXTO MUITO CURTO - provavelmente resumo, n√£o texto original")
            elif len(texto_bruto) < 2000:
                print("‚ö†Ô∏è TEXTO CURTO - pode ser resumo ou texto truncado")
            else:
                print("‚úÖ TEXTO LONGO - pode ser texto original")
            
            # Verifica se parece resumo
            palavras_resumo = ['not√≠cia', 'mat√©ria', 'artigo', 'pe√ßa', 'apresenta', 'incluindo']
            if any(palavra in texto_bruto.lower() for palavra in palavras_resumo):
                print("üö® PARECE SER RESUMO (cont√©m palavras t√≠picas de resumo)")
            else:
                print("‚úÖ PARECE SER TEXTO ORIGINAL (n√£o cont√©m palavras de resumo)")
                
        else:
            print("‚ùå TEXTO BRUTO: N√ÉO DEFINIDO")
        
        # AN√ÅLISE DETALHADA DO TEXTO PROCESSADO
        print_section("üìù AN√ÅLISE DETALHADA DO TEXTO PROCESSADO")
        if artigo.texto_processado:
            texto_processado = artigo.texto_processado
            print(f"ÔøΩÔøΩ Tamanho: {len(texto_processado)} caracteres")
            print(f"üìù Primeiros 200 chars: {texto_processado[:200]}")
            print(f"ÔøΩÔøΩ √öltimos 200 chars: {texto_processado[-200:]}")
            
            # An√°lise de conte√∫do
            if len(texto_processado) < 500:
                print("‚úÖ TEXTO CURTO - provavelmente resumo (correto)")
            else:
                print("‚ö†Ô∏è TEXTO LONGO - pode ser texto original (incorreto)")
                
        else:
            print("‚ùå TEXTO PROCESSADO: N√ÉO DEFINIDO")
        
        # COMPARA√á√ÉO DETALHADA
        print_section("üîç COMPARA√á√ÉO DETALHADA")
        if artigo.texto_bruto and artigo.texto_processado:
            if artigo.texto_bruto == artigo.texto_processado:
                print("üö® PROBLEMA CR√çTICO: texto_bruto e texto_processado s√£o ID√äNTICOS!")
                print("   Isso significa que:")
                print("   - OU ambos cont√™m resumos (texto_bruto deveria ter texto original)")
                print("   - OU ambos cont√™m texto original (texto_processado deveria ter resumo)")
            else:
                print("‚úÖ OK: texto_bruto e texto_processado s√£o diferentes")
                
                # Verifica qual √© qual
                if len(artigo.texto_bruto) > len(artigo.texto_processado):
                    print("   ‚úÖ texto_bruto > texto_processado (correto)")
                else:
                    print("   ‚ö†Ô∏è texto_processado > texto_bruto (pode estar incorreto)")
                    
                # Verifica similaridade
                from difflib import SequenceMatcher
                similaridade = SequenceMatcher(None, artigo.texto_bruto, artigo.texto_processado).ratio()
                print(f"   ÔøΩÔøΩ Similaridade entre os textos: {similaridade:.2%}")
                
                if similaridade > 0.8:
                    print("   ‚ö†Ô∏è ATEN√á√ÉO: Textos muito similares (pode haver problema)")
                elif similaridade < 0.3:
                    print("   ‚úÖ OK: Textos bem diferentes (correto)")
                else:
                    print("   ‚ö†Ô∏è ATEN√á√ÉO: Textos moderadamente similares")
        
        # AN√ÅLISE DOS METADADOS
        print_section("üîß AN√ÅLISE DETALHADA DOS METADADOS")
        if artigo.metadados:
            metadados = artigo.metadados
            print("üìã Metadados dispon√≠veis:")
            for chave, valor in metadados.items():
                if isinstance(valor, str) and len(valor) > 100:
                    print(f"   {chave}: {valor[:100]}... [TRUNCADO - {len(valor)} chars]")
                else:
                    print(f"   {chave}: {valor}")
            
            # Verifica campos importantes
            campos_importantes = ['texto_completo', 'arquivo_origem', 'tipo_arquivo', 'data_processamento']
            for campo in campos_importantes:
                if campo in metadados:
                    print(f"‚úÖ Campo '{campo}' encontrado: {metadados[campo]}")
                else:
                    print(f"‚ùå Campo '{campo}' N√ÉO encontrado")
                    
            # Verifica se tem texto completo nos metadados
            if 'texto_completo' in metadados:
                texto_completo_meta = metadados['texto_completo']
                print(f"\nÔøΩÔøΩ TEXTO COMPLETO dos metadados:")
                print(f"   ÔøΩÔøΩ Tamanho: {len(texto_completo_meta)} caracteres")
                print(f"   üìù Primeiros 200 chars: {texto_completo_meta[:200]}")
                
                # Compara com texto_bruto
                if artigo.texto_bruto:
                    if texto_completo_meta == artigo.texto_bruto:
                        print("   ‚úÖ texto_completo dos metadados = texto_bruto (correto)")
                    else:
                        print("   üö® PROBLEMA: texto_completo dos metadados ‚â† texto_bruto")
                        print("   Isso significa que o texto_bruto foi alterado ap√≥s a ingest√£o!")
                        
                        # Verifica qual √© mais longo
                        if len(texto_completo_meta) > len(artigo.texto_bruto):
                            print("   ÔøΩÔøΩ texto_completo dos metadados > texto_bruto")
                            print("   ÔøΩÔøΩ PROBLEMA: texto_bruto foi TRUNCADO ou RESUMIDO!")
                        else:
                            print("   ÔøΩÔøΩ texto_completo dos metadados < texto_bruto")
                            print("   ‚ö†Ô∏è ATEN√á√ÉO: texto_bruto foi EXPANDIDO (pode estar incorreto)")
            else:
                print("‚ùå Campo 'texto_completo' N√ÉO encontrado nos metadados")
                
        else:
            print("‚ùå METADADOS: N√ÉO DEFINIDO")
        
        # AN√ÅLISE DO FLUXO
        print_section("üîÑ AN√ÅLISE DO FLUXO DE PROCESSAMENTO")
        
        # Verifica se foi processado
        if artigo.status == 'processado':
            print("ÔøΩÔøΩ Status: processado")
            print("   ‚úÖ Artigo foi processado pelo process_articles.py")
            
            # Verifica se tem cluster
            if artigo.cluster_id:
                print(f"   üîó Associado ao cluster {artigo.cluster_id}")
                
                # Busca dados do cluster
                cluster = get_cluster_by_id(db, artigo.cluster_id)
                if cluster:
                    print(f"   ÔøΩÔøΩ T√≠tulo do cluster: {cluster.titulo_cluster}")
                    if cluster.resumo_cluster:
                        print(f"   ÔøΩÔøΩ Resumo do cluster: {cluster.resumo_cluster[:200]}...")
                    else:
                        print("   ‚ùå Cluster sem resumo")
                else:
                    print("   ‚ùå Cluster n√£o encontrado")
            else:
                print("   ‚ùå N√ÉO associado a cluster")
        else:
            print(f"üìä Status: {artigo.status}")
            print("   ‚ö†Ô∏è Artigo N√ÉO foi processado ainda")
        
        db.close()
        return True
        
    except Exception as e:
        print(f"‚ùå ERRO ao investigar artigo: {e}")
        import traceback
        traceback.print_exc()
        return False

def investigar_artigos_por_fonte():
    """Investiga artigos por fonte de coleta para entender padr√µes"""
    print_header("ÔøΩÔøΩ INVESTIGA√á√ÉO POR FONTE DE COLETA")
    
    try:
        db = SessionLocal()
        
        # Busca fontes de coleta √∫nicas
        query = text("""
            SELECT 
                fonte_coleta,
                COUNT(*) as total,
                COUNT(CASE WHEN texto_bruto IS NOT NULL THEN 1 END) as com_texto_bruto,
                COUNT(CASE WHEN texto_processado IS NOT NULL THEN 1 END) as com_texto_processado,
                AVG(LENGTH(texto_bruto)) as avg_tamanho_bruto,
                AVG(LENGTH(texto_processado)) as avg_tamanho_processado,
                MIN(created_at) as primeiro,
                MAX(created_at) as ultimo
            FROM artigos_brutos
            GROUP BY fonte_coleta
            ORDER BY total DESC
            LIMIT 10
        """)
        
        fontes = db.execute(query).fetchall()
        
        print("üìä An√°lise por fonte de coleta:")
        for fonte in fontes:
            print(f"\nüì∞ FONTE: {fonte.fonte_coleta}")
            print(f"   üìä Total: {fonte.total}")
            print(f"   ÔøΩÔøΩ Com texto_bruto: {fonte.com_texto_bruto}")
            print(f"   üìù Com texto_processado: {fonte.com_texto_processado}")
            print(f"   üìè Tamanho m√©dio texto_bruto: {fonte.avg_tamanho_bruto:.0f} chars")
            print(f"   üìè Tamanho m√©dio texto_processado: {fonte.avg_tamanho_processado:.0f} chars")
            print(f"   üìÖ Per√≠odo: {fonte.primeiro} at√© {fonte.ultimo}")
            
            # An√°lise de padr√£o
            if fonte.avg_tamanho_bruto < 1000:
                print("   ‚ö†Ô∏è ATEN√á√ÉO: texto_bruto muito curto (pode ser resumo)")
            elif fonte.avg_tamanho_bruto > 5000:
                print("   ‚úÖ OK: texto_bruto longo (pode ser texto original)")
            else:
                print("   ‚ö†Ô∏è ATEN√á√ÉO: texto_bruto tamanho m√©dio (pode estar truncado)")
                
            if fonte.avg_tamanho_processado > 1000:
                print("   ‚ö†Ô∏è ATEN√á√ÉO: texto_processado muito longo (pode ser texto original)")
            else:
                print("   ‚úÖ OK: texto_processado curto (pode ser resumo)")
        
        db.close()
        
    except Exception as e:
        print(f"‚ùå ERRO ao investigar por fonte: {e}")

def investigar_artigos_por_tipo():
    """Investiga artigos por tipo de arquivo (PDF vs JSON)"""
    print_header("ÔøΩÔøΩ INVESTIGA√á√ÉO POR TIPO DE ARQUIVO")
    
    try:
        db = SessionLocal()
        
        # Busca artigos com metadados que indiquem tipo
        query = text("""
            SELECT 
                metadados->>'tipo_arquivo' as tipo,
                COUNT(*) as total,
                AVG(LENGTH(texto_bruto)) as avg_tamanho_bruto,
                AVG(LENGTH(texto_processado)) as avg_tamanho_processado,
                COUNT(CASE WHEN LENGTH(texto_bruto) < 1000 THEN 1 END) as texto_bruto_curto,
                COUNT(CASE WHEN LENGTH(texto_bruto) > 5000 THEN 1 END) as texto_bruto_longo
            FROM artigos_brutos
            WHERE metadados IS NOT NULL
            GROUP BY metadados->>'tipo_arquivo'
            ORDER BY total DESC
        """)
        
        tipos = db.execute(query).fetchall()
        
        print("üìä An√°lise por tipo de arquivo:")
        for tipo in tipos:
            if not tipo.tipo:
                continue
                
            print(f"\nüìÅ TIPO: {tipo.tipo}")
            print(f"   ÔøΩÔøΩ Total: {tipo.total}")
            print(f"   üìè Tamanho m√©dio texto_bruto: {tipo.avg_tamanho_bruto:.0f} chars")
            print(f"   üìè Tamanho m√©dio texto_processado: {tipo.avg_tamanho_processado:.0f} chars")
            print(f"   ‚ö†Ô∏è texto_bruto curto (<1000): {tipo.texto_bruto_curto}")
            print(f"   ‚úÖ texto_bruto longo (>5000): {tipo.texto_bruto_longo}")
            
            # An√°lise espec√≠fica por tipo
            if tipo.tipo == 'pdf':
                if tipo.avg_tamanho_bruto < 2000:
                    print("   ÔøΩÔøΩ PROBLEMA: PDFs com texto_bruto muito curto!")
                    print("   üí° Isso sugere que o OCR/LLM est√° resumindo em vez de extrair texto completo")
                else:
                    print("   ‚úÖ OK: PDFs com texto_bruto longo (texto completo extra√≠do)")
                    
            elif tipo.tipo == 'json':
                if tipo.avg_tamanho_bruto > 2000:
                    print("   ‚úÖ OK: JSONs com texto_bruto longo (texto completo preservado)")
                else:
                    print("   ‚ö†Ô∏è ATEN√á√ÉO: JSONs com texto_bruto curto (pode estar sendo processado)")
        
        db.close()
        
    except Exception as e:
        print(f"‚ùå ERRO ao investigar por tipo: {e}")

def investigar_artigos_recentes():
    """Investiga artigos criados recentemente para entender o padr√£o atual"""
    print_header("üïê INVESTIGA√á√ÉO DE ARTIGOS RECENTES")
    
    try:
        db = SessionLocal()
        
        # Busca artigos das √∫ltimas 24h
        query = text("""
            SELECT 
                id,
                fonte_coleta,
                metadados->>'tipo_arquivo' as tipo,
                LENGTH(texto_bruto) as tamanho_bruto,
                LENGTH(texto_processado) as tamanho_processado,
                status,
                created_at
            FROM artigos_brutos
            WHERE created_at >= NOW() - INTERVAL '24 hours'
            ORDER BY created_at DESC
            LIMIT 20
        """)
        
        artigos_recentes = db.execute(query).fetchall()
        
        print(f"üìä Artigos criados nas √∫ltimas 24h: {len(artigos_recentes)}")
        
        for artigo in artigos_recentes:
            print(f"\nÔøΩÔøΩ Artigo {artigo.id} ({artigo.created_at.strftime('%H:%M')})")
            print(f"   üì∞ Fonte: {artigo.fonte_coleta}")
            print(f"   ÔøΩÔøΩ Tipo: {artigo.tipo or 'N/A'}")
            print(f"   üìè Tamanho texto_bruto: {artigo.tamanho_bruto} chars")
            print(f"   üìè Tamanho texto_processado: {artigo.tamanho_processado} chars")
            print(f"   üìä Status: {artigo.status}")
            
            # An√°lise r√°pida
            if artigo.tamanho_bruto < 1000:
                print("   ‚ö†Ô∏è texto_bruto muito curto")
            elif artigo.tamanho_bruto > 5000:
                print("   ‚úÖ texto_bruto longo")
            else:
                print("   ‚ö†Ô∏è texto_bruto tamanho m√©dio")
                
            if artigo.tamanho_processado and artigo.tamanho_processado > 1000:
                print("   ‚ö†Ô∏è texto_processado muito longo")
            elif artigo.tamanho_processado:
                print("   ‚úÖ texto_processado adequado")
            else:
                print("   ‚ùå texto_processado n√£o definido")
        
        db.close()
        
    except Exception as e:
        print(f"‚ùå ERRO ao investigar artigos recentes: {e}")

def main():
    """Fun√ß√£o principal da investiga√ß√£o"""
    print_header("üî¨ INVESTIGA√á√ÉO PROFUNDA DO FLUXO DE DADOS", "=", 80)
    print(f"üìÖ Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. Investigar artigo espec√≠fico (do diagn√≥stico anterior)
    artigo_id = 7108  # Artigo que mostrou problema no diagn√≥stico
    print(f"\nÔøΩÔøΩ INVESTIGANDO ARTIGO ESPEC√çFICO: {artigo_id}")
    investigar_artigo_especifico(artigo_id)
    
    # 2. Investigar por fonte de coleta
    print_header("ÔøΩÔøΩ INVESTIGA√á√ÉO POR FONTE")
    investigar_artigos_por_fonte()
    
    # 3. Investigar por tipo de arquivo
    print_header("ÔøΩÔøΩ INVESTIGA√á√ÉO POR TIPO")
    investigar_artigos_por_tipo()
    
    # 4. Investigar artigos recentes
    print_header("üïê INVESTIGA√á√ÉO RECENTE")
    investigar_artigos_recentes()
    
    # 5. RESUMO FINAL
    print_header("ÔøΩÔøΩ RESUMO DA INVESTIGA√á√ÉO", "=", 80)
    print("‚úÖ INVESTIGA√á√ÉO CONCLU√çDA!")
    print("\nüîç PR√ìXIMOS PASSOS:")
    print("1. Analise os resultados acima")
    print("2. Identifique padr√µes nos problemas")
    print("3. Determine se o problema est√° em:")
    print("   - load_news.py (ingest√£o)")
    print("   - process_articles.py (processamento)")
    print("   - Ambos")
    print("4. Planeje corre√ß√µes espec√≠ficas")
    
    print("\nüö® PROBLEMAS ESPERADOS:")
    print("- PDFs sendo processados por LLM na ingest√£o")
    print("- texto_bruto sendo sobrescrito no processamento")
    print("- Falta de preserva√ß√£o do texto original")
    print("- Metadados n√£o sendo usados corretamente")

if __name__ == "__main__":
    main()