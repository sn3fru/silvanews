"""
Fun√ß√µes auxiliares para o BTG AlphaFeed.
Migrado de silva.py para arquitetura de API.
"""

import re
import os
import json
import hashlib
from typing import Any, Dict, Optional
import PyPDF2
from datetime import datetime, timezone, timedelta


def corrigir_tag_invalida(tag_original: str) -> str:
    """
    Mapeia tags inv√°lidas ou similares para as tags v√°lidas do TAGS_SPECIAL_SITUATIONS.
    
    Args:
        tag_original: Tag original que pode estar inv√°lida
        
    Returns:
        Tag v√°lida mapeada
    """
    if not tag_original or not isinstance(tag_original, str):
        return 'Internacional (Economia e Pol√≠tica)'  # Tag padr√£o das novas
    
    tag_limpa = tag_original.strip().lower()
    
    # Mapeamento de tags similares para as novas tags especializadas
    MAPEAMENTO_TAGS = {
        # Pol√≠tica Econ√¥mica (Brasil)
        'governo e politica': 'Pol√≠tica Econ√¥mica (Brasil)',
        'governo e pol√≠tica': 'Pol√≠tica Econ√¥mica (Brasil)', 
        'pol√≠tica': 'Pol√≠tica Econ√¥mica (Brasil)',
        'politica': 'Pol√≠tica Econ√¥mica (Brasil)',
        'governo': 'Pol√≠tica Econ√¥mica (Brasil)',
        'pol√≠tica econ√¥mica': 'Pol√≠tica Econ√¥mica (Brasil)',
        'politica economica': 'Pol√≠tica Econ√¥mica (Brasil)',
        'pol√≠tica p√∫blica': 'Pol√≠tica Econ√¥mica (Brasil)',
        'pol√≠tica publica': 'Pol√≠tica Econ√¥mica (Brasil)',
        
        # Internacional (Economia e Pol√≠tica)
        'economia e tecnologia': 'Internacional (Economia e Pol√≠tica)',
        'economia': 'Internacional (Economia e Pol√≠tica)',
        'tecnologia': 'Tecnologia e Setores Estrat√©gicos',
        'tech': 'Tecnologia e Setores Estrat√©gicos',
        'ia': 'Tecnologia e Setores Estrat√©gicos',
        'intelig√™ncia artificial': 'Tecnologia e Setores Estrat√©gicos',
        'inteligencia artificial': 'Tecnologia e Setores Estrat√©gicos',
        'cripto': 'Internacional (Economia e Pol√≠tica)',
        'criptomoedas': 'Internacional (Economia e Pol√≠tica)',
        'bitcoin': 'Internacional (Economia e Pol√≠tica)',
        
        # Jur√≠dico, Fal√™ncias e Regulat√≥rio
        'judicionario': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'judici√°rio': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'judicial': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'justi√ßa': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'justica': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'tribunal': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'stf': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'stj': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'supremo': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'superior tribunal': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'tj': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'trf': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'vara': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'recupera√ß√£o judicial': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'recuperacao judicial': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'fal√™ncia': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'falencia': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'legislativo': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'congresso': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'senado': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'c√¢mara': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        'camara': 'Jur√≠dico, Fal√™ncias e Regulat√≥rio',
        
        # Mercado de Capitais e Finan√ßas Corporativas
        'empresas privadas': 'Mercado de Capitais e Finan√ßas Corporativas',
        'empresas': 'Mercado de Capitais e Finan√ßas Corporativas',
        'corporativo': 'Mercado de Capitais e Finan√ßas Corporativas',
        'neg√≥cios': 'Mercado de Capitais e Finan√ßas Corporativas',
        'negocios': 'Mercado de Capitais e Finan√ßas Corporativas',
        'mercado': 'Mercado de Capitais e Finan√ßas Corporativas',
        'setor privado': 'Mercado de Capitais e Finan√ßas Corporativas',
        
        # M&A e Transa√ß√µes Corporativas
        'm&a': 'M&A e Transa√ß√µes Corporativas',
        'fus√£o': 'M&A e Transa√ß√µes Corporativas',
        'fusao': 'M&A e Transa√ß√µes Corporativas',
        'aquisi√ß√£o': 'M&A e Transa√ß√µes Corporativas',
        'aquisicao': 'M&A e Transa√ß√µes Corporativas',
    }
    
    # Busca correspond√™ncia exata primeiro
    if tag_limpa in MAPEAMENTO_TAGS:
        return MAPEAMENTO_TAGS[tag_limpa]
    
    # Se n√£o encontrar correspond√™ncia exata, busca por palavras-chave
    for palavra_chave, tag_correta in MAPEAMENTO_TAGS.items():
        if palavra_chave in tag_limpa:
            return tag_correta
    
    # Se nada corresponder, classifica como IRRELEVANTE
    return 'IRRELEVANTE'


def corrigir_prioridade_invalida(prioridade_original: Optional[str]) -> str:
    """
    Normaliza a prioridade. Se n√£o for uma das v√°lidas (P1_CRITICO, P2_ESTRATEGICO, P3_MONITORAMENTO),
    retorna 'IRRELEVANTE'.
    """
    validas = {'P1_CRITICO', 'P2_ESTRATEGICO', 'P3_MONITORAMENTO'}
    if isinstance(prioridade_original, str) and prioridade_original in validas:
        return prioridade_original
    return 'IRRELEVANTE'


def limpar_nome_arquivo(nome: str) -> str:
    """Remove caracteres especiais e limita o comprimento do nome do arquivo."""
    if not nome:
        return "arquivo_sem_nome"
    
    # Remove caracteres especiais, mant√©m apenas alphanumm√©ricos, h√≠fens, underscores e pontos
    nome = re.sub(r'[^\w\-_.]', '', nome)
    return nome[:150]


def extrair_json_da_resposta(resposta: str) -> Any:
    """
    Tenta extrair e decodificar um objeto JSON de uma string de resposta do LLM,
    que pode estar envolto em markdown, texto solto ou ser truncado.
    Inclui depura√ß√£o detalhada em caso de falha.
    """
    # ETAPA 0: Valida√ß√£o inicial da resposta
    if not isinstance(resposta, str) or not resposta.strip():
        print("‚ùå Erro ao extrair JSON: A resposta recebida da API est√° vazia ou n√£o √© uma string.")
        return None

    json_str = ""
    # ETAPA 1: Tenta encontrar um bloco de c√≥digo JSON expl√≠cito (```json ... ```)
    match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', resposta, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
    else:
        # ETAPA 2 (Fallback): Se n√£o houver bloco de c√≥digo, busca o primeiro '[' ou '{'
        start_bracket = resposta.find('[')
        start_brace = resposta.find('{')
        
        start = -1
        if start_bracket != -1 and (start_bracket < start_brace or start_brace == -1):
            start = start_bracket
        elif start_brace != -1:
            start = start_brace

        if start != -1:
            json_str = resposta[start:].strip()
        else:
            print("‚ùå Erro ao extrair JSON: Nenhum marcador de in√≠cio ('[' ou '{') foi encontrado.")
            print("üìã RESPOSTA COMPLETA DA API (para depura√ß√£o):")
            print("-" * 50)
            print(resposta)
            print("-" * 50)
            return None

    # ETAPA 3: Tenta decodificar o JSON extra√≠do
    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        print(f"‚ùå Erro ao decodificar JSON: {e}")
        print(f"üìã String que tentou decodificar:")
        print("-" * 50)
        print(json_str)
        print("-" * 50)
        return None


def verificar_dependencias():
    """
    Verifica se todas as depend√™ncias necess√°rias est√£o instaladas.
    """
    try:
        import google.generativeai as genai
        import PyPDF2
        import docx
        from sentence_transformers import SentenceTransformer
        import numpy as np
        import sqlalchemy
        print("‚úÖ Todas as depend√™ncias est√£o dispon√≠veis.")
        return True
    except ImportError as e:
        print(f"‚ùå Depend√™ncia faltando: {e}")
        print("Execute: pip install -r requirements.txt")
        return False


def contar_paginas_pdf(caminho_pdf: str) -> int:
    """
    Conta o n√∫mero de p√°ginas de um arquivo PDF.
    
    Args:
        caminho_pdf: Caminho para o arquivo PDF
        
    Returns:
        N√∫mero de p√°ginas do PDF
    """
    try:
        with open(caminho_pdf, 'rb') as arquivo:
            leitor_pdf = PyPDF2.PdfReader(arquivo)
            return len(leitor_pdf.pages)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao contar p√°ginas do PDF {caminho_pdf}: {e}")
        return 0


def migrar_noticia_cache_legado(noticia_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Migra uma not√≠cia do cache legado para o formato atual.
    Garante que todos os campos obrigat√≥rios estejam presentes.
    
    Args:
        noticia_data: Dados da not√≠cia no formato legado
        
    Returns:
        Dados da not√≠cia no formato atual
    """
    # Campos obrigat√≥rios com valores padr√£o
    campos_obrigatorios = {
        'titulo': noticia_data.get('titulo', ''),
        'texto_completo': noticia_data.get('texto_completo', ''),
        'jornal': noticia_data.get('jornal', 'N/A'),
        'autor': noticia_data.get('autor', 'N/A'),
        'pagina': noticia_data.get('pagina'),
        'data': noticia_data.get('data'),
        'categoria': noticia_data.get('categoria'),
        'tag': noticia_data.get('tag', 'Empresas Privadas'),
        'prioridade': noticia_data.get('prioridade', 'P3_MONITORAMENTO'),
        'relevance_score': noticia_data.get('relevance_score'),
        'relevance_reason': noticia_data.get('relevance_reason')
    }
    
    # Atualiza com os dados originais, mantendo os padr√µes se n√£o existirem
    noticia_migrada = {**campos_obrigatorios, **noticia_data}
    
    # Corrige a tag se necess√°rio
    noticia_migrada['tag'] = corrigir_tag_invalida(noticia_migrada['tag'])
    
    # Define relevance_reason padr√£o baseado na prioridade se n√£o existir
    if not noticia_migrada.get('relevance_reason'):
        prioridade = noticia_migrada.get('prioridade', 'P3_MONITORAMENTO')
        noticia_migrada['relevance_reason'] = f"Migrado: Classificado como {prioridade}"
    
    return noticia_migrada


def gerar_hash_unico(texto: str, url: Optional[str] = None) -> str:
    """
    Gera um hash √∫nico para identificar artigos duplicados.
    
    Args:
        texto: Texto do artigo
        url: URL opcional do artigo
        
    Returns:
        Hash SHA256 do conte√∫do
    """
    conteudo = f"{texto}{url or ''}"
    return hashlib.sha256(conteudo.encode('utf-8')).hexdigest()


def formatar_timestamp_relativo(timestamp_str: str) -> str:
    """
    Converte um timestamp para formato relativo (h√° X minutos/horas).
    
    Args:
        timestamp_str: Timestamp em formato ISO ou similar
        
    Returns:
        String no formato "h√° X minutos/horas"
    """
    from datetime import datetime, timezone
    
    try:
        # Tenta parsear diferentes formatos de timestamp
        if 'T' in timestamp_str:
            timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        else:
            timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
            timestamp = timestamp.replace(tzinfo=timezone.utc)
        
        agora = datetime.now(timezone.utc)
        diferenca = agora - timestamp
        
        if diferenca.days > 0:
            return f"h√° {diferenca.days} dias"
        elif diferenca.seconds >= 3600:
            horas = diferenca.seconds // 3600
            return f"h√° {horas} horas"
        elif diferenca.seconds >= 60:
            minutos = diferenca.seconds // 60
            return f"h√° {minutos} minutos"
        else:
            return "h√° poucos segundos"
            
    except Exception:
        return "timestamp inv√°lido"


def sanitizar_html(texto: str) -> str:
    """
    Remove tags HTML e caracteres especiais do texto.
    
    Args:
        texto: Texto com poss√≠veis tags HTML
        
    Returns:
        Texto limpo
    """
    if not texto:
        return ""
    
    # Remove tags HTML
    texto_limpo = re.sub(r'<[^>]+>', '', texto)
    
    # Remove caracteres especiais e m√∫ltiplos espa√ßos
    texto_limpo = re.sub(r'\s+', ' ', texto_limpo)
    
    return texto_limpo.strip()


def truncar_texto(texto: str, max_length: int = 500, sufixo: str = "...") -> str:
    """
    Trunca um texto para um comprimento m√°ximo.
    
    Args:
        texto: Texto a ser truncado
        max_length: Comprimento m√°ximo
        sufixo: Sufixo a ser adicionado se truncado
        
    Returns:
        Texto truncado
    """
    if not texto or len(texto) <= max_length:
        return texto
    
    return texto[:max_length - len(sufixo)] + sufixo


def get_gemini_model():
    """
    Configura e retorna o modelo Gemini para uso no chat.
    
    Returns:
        Modelo Gemini configurado
    """
    import os
    import google.generativeai as genai
    
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY n√£o configurada")
    
    genai.configure(api_key=api_key)
    return genai.GenerativeModel('gemini-2.0-flash-lite')

# ==============================================================================
# UTILIT√ÅRIOS DE DATA E FUSO HOR√ÅRIO (GMT-3)
# ==============================================================================

# Fuso hor√°rio de S√£o Paulo/Bras√≠lia (GMT-3)
SAO_PAULO_TZ = timezone(timedelta(hours=-3))

def get_datetime_brasil() -> datetime:
    """
    Retorna datetime atual no fuso hor√°rio de S√£o Paulo/Bras√≠lia (GMT-3).
    """
    return datetime.now(SAO_PAULO_TZ)

def get_date_brasil() -> datetime.date:
    """
    Retorna data atual no fuso hor√°rio de S√£o Paulo/Bras√≠lia (GMT-3).
    """
    dt_brasil = get_datetime_brasil()
    return dt_brasil.date()

def get_datetime_brasil_str() -> str:
    """
    Retorna datetime atual como string ISO no fuso hor√°rio de S√£o Paulo/Bras√≠lia.
    """
    return get_datetime_brasil().isoformat()

def get_date_brasil_str() -> str:
    """
    Retorna data atual como string YYYY-MM-DD no fuso hor√°rio de S√£o Paulo/Bras√≠lia.
    """
    return get_date_brasil().strftime('%Y-%m-%d')

def convert_to_brasil_tz(dt: datetime) -> datetime:
    """
    Converte um datetime para o fuso hor√°rio de S√£o Paulo/Bras√≠lia.
    Se o datetime n√£o tem timezone, assume que √© UTC.
    """
    if dt.tzinfo is None:
        # Assume UTC se n√£o tem timezone
        dt = dt.replace(tzinfo=timezone.utc)
    
    return dt.astimezone(SAO_PAULO_TZ)

def format_datetime_brasil(dt: datetime, format_str: str = "%Y-%m-%d %H:%M:%S") -> str:
    """
    Formata um datetime para string no fuso hor√°rio de S√£o Paulo/Bras√≠lia.
    """
    dt_brasil = convert_to_brasil_tz(dt)
    return dt_brasil.strftime(format_str)

def parse_date_brasil(date_str: str) -> datetime.date:
    """
    Converte string de data para objeto date, assumindo fuso hor√°rio de S√£o Paulo.
    """
    try:
        # Tenta diferentes formatos
        for fmt in ['%Y-%m-%d', '%d/%m/%Y', '%Y-%m-%d %H:%M:%S']:
            try:
                dt = datetime.strptime(date_str, fmt)
                if fmt == '%Y-%m-%d':
                    return dt.date()
                else:
                    return convert_to_brasil_tz(dt).date()
            except ValueError:
                continue
        raise ValueError(f"Formato de data n√£o reconhecido: {date_str}")
    except Exception as e:
        raise ValueError(f"Erro ao converter data '{date_str}': {e}")

def get_timestamp_brasil() -> str:
    """
    Retorna timestamp atual no formato YYYY-MM-DD_HHhMMm no fuso hor√°rio de S√£o Paulo.
    """
    return get_datetime_brasil().strftime("%Y-%m-%d_%Hh%Mm")

def get_datetime_formatted_brasil() -> str:
    """
    Retorna datetime atual formatado como dd/mm/yyyy √†s HH:MM no fuso hor√°rio de S√£o Paulo.
    """
    return get_datetime_brasil().strftime("%d/%m/%Y √†s %H:%M")