from __future__ import annotations

"""
Agente 'Estagi√°rio' ‚Äî Conversa sobre TODAS as not√≠cias do dia (em constru√ß√£o)

Objetivo:
- Fornecer uma interface de consulta inteligente sobre os eventos do dia
  sem alterar a l√≥gica atual do pipeline/FE.

Regras:
- N√£o duplica l√≥gica de neg√≥cio do pipeline
- Consulta o banco via fun√ß√µes existentes do backend
- Seleciona apenas dados √∫teis por prioridade/tag conforme a pergunta

Status: EM CONSTRU√á√ÉO üöß
"""

from dataclasses import dataclass
from typing import List, Optional, Dict, Any
from datetime import datetime
from pathlib import Path
import os

try:
    # Imports relativos ao backend j√° existente
    from backend.database import SessionLocal
    from backend.crud import (
        get_clusters_for_feed_by_date,
        get_cluster_details_by_id,
        get_metricas_by_date,
    )
    from backend.utils import get_date_brasil
    # Opcional: acesso direto ao modelo para contagens precisas
    from backend.database import ClusterEvento
except Exception:
    # Evita crash em ambientes onde backend n√£o est√° configurado
    SessionLocal = None # type: ignore


@dataclass
class AgentAnswer:
    ok: bool
    text: str
    data: Optional[Dict[str, Any]] = None


class EstagiarioAgent:
    """Agente de consulta de alto n√≠vel sobre as not√≠cias do dia."""

    def __init__(self) -> None:
        if SessionLocal is None:
            raise RuntimeError("Backend indispon√≠vel para Estagi√°rioAgent")
        # Carrega KB
        try:
            kb_path = Path(__file__).parent / "knowledge" / "KB_SITE.md"
            self.kb_text = kb_path.read_text(encoding="utf-8")
            print(f"[Estagiario] KB carregado: {kb_path}")
        except Exception as e:
            self.kb_text = ""
            print(f"[Estagiario] KB indispon√≠vel: {e}")
        # LLM opcional
        self.model = None
        try:
            import google.generativeai as genai  # type: ignore
            api_key = os.getenv("GEMINI_API_KEY")
            if api_key:
                genai.configure(api_key=api_key)
                self.model = genai.GenerativeModel('gemini-2.0-flash')
                print("[Estagiario] LLM configurado (Gemini)")
            else:
                print("[Estagiario] LLM n√£o configurado (GEMINI_API_KEY ausente)")
        except Exception as e:
            print(f"[Estagiario] LLM indispon√≠vel: {e}")

        # Cat√°logo de prioridades e tags permitidas
        self.prioridades_permitidas = [
            "P1_CRITICO", "P2_ESTRATEGICO", "P3_MONITORAMENTO", "IRRELEVANTE"
        ]
        try:
            from backend.prompts import TAGS_SPECIAL_SITUATIONS  # type: ignore
            self.tags_permitidas = [t.get('nome') for t in TAGS_SPECIAL_SITUATIONS if isinstance(t, dict) and t.get('nome')]
        except Exception:
            self.tags_permitidas = [
                "Jur√≠dico", "M&A", "Mercado de Capitais", "Pol√≠tica Econ√¥mica",
                "Internacional", "Tecnologia e Setores Estrat√©gicos", "Distressed Assets", "Outros"
            ]

    def _open_db(self):
        print("[Estagiario] Abrindo sess√£o DB...")
        return SessionLocal()

    def _fetch_clusters(
        self,
        db,
        target_date: Optional[datetime.date] = None,
        priority: Optional[str] = None,
        page_size: int = 100,
    ) -> List[Dict[str, Any]]:
        """Carrega todas as p√°ginas para a prioridade informada (ou todas)."""
        if target_date is None:
            target_date = get_date_brasil()

        page = 1
        itens: List[Dict[str, Any]] = []
        print(f"[Estagiario] Fetch clusters date={target_date.isoformat()} priority={priority or 'ALL'} page_size={page_size}")
        while True:
            resp = get_clusters_for_feed_by_date(
                db, target_date, page=page, page_size=page_size, load_full_text=False, priority=priority
            )
            clusters = resp.get("clusters", [])
            itens.extend(clusters)
            pag = resp.get("paginacao", {})
            print(f"[Estagiario]  page={page} carregados={len(clusters)} acumulado={len(itens)} tem_proxima={bool(pag.get('tem_proxima'))}")
            if not pag or not pag.get("tem_proxima"):
                break
            page += 1
        return itens

    def _llm_answer(self, question: str, retrieved: List[Dict[str, Any]]) -> Optional[str]:
        if not self.model:
            return None
        try:
            # Monta contexto curto com itens recuperados
            exemplos = []
            for it in retrieved[:12]:
                exemplos.append({
                    "id": it.get("id"),
                    "titulo": it.get("titulo") or it.get("titulo_final"),
                    "resumo": it.get("resumo") or it.get("resumo_final"),
                    "tag": it.get("tag"),
                    "prioridade": it.get("prioridade"),
                    "fontes": it.get("fontes", []),
                    "artigos": it.get("artigos", []),
                })
            prompt = (
                "Voc√™ √© um analista do BTG na mesa de Special Situations. Produza um RELAT√ìRIO em Markdown, direto ao ponto,"
                " usando as not√≠cias como insumos. V√° al√©m de listar not√≠cias; sintetize insights e impactos.\n\n"
                "KB (resumo):\n" + (self.kb_text[:6000]) + "\n\n"
                "Amostra de dados (clusters do dia):\n" + str(exemplos) + "\n\n"
                "Instru√ß√µes de resposta (obrigat√≥rio):\n"
                "- Proibido descrever etapas, ferramentas ou plano.\n"
                "- Estruture com (exemplo de se√ß√µes): ## Panorama, ## Principais Sinais (bullets), ## Pre√ßos/Promo√ß√µes (tabela, se cab√≠vel), ## Riscos, ## Oportunidades, ## A√ß√µes sugeridas.\n"
                "- Traga nomes de autores e jornais quando dispon√≠veis; cite prioridades/tags quando agregarem contexto.\n"
                "- Evite frases como 'Com base nos dados fornecidos'.\n"
                "- Finalize com 'Not√≠cias pesquisadas:' numerada no formato [ID] T√≠tulo ‚Äî URL (Jornal).\n\n"
                "Pergunta do usu√°rio: " + question + "\n"
            )
            print("[Estagiario] S√≠ntese LLM iniciada...")
            resp = self.model.generate_content(prompt, generation_config={
                'temperature': 0.3,
                'top_p': 0.8,
                'max_output_tokens': 5_000
            })
            txt = (resp.text or "").strip()
            print(f"[Estagiario] S√≠ntese LLM conclu√≠da. Len={len(txt)}")
            return txt or None
        except Exception as e:
            print(f"[Estagiario] Falha LLM: {e}")
            return None

    def _compose_markdown_from_retrieved(self, question: str, retrieved: List[Dict[str, Any]]) -> str:
        titulo_secao = "## Resposta"
        bullets: List[str] = []
        fontes_items: List[str] = []
        for it in retrieved[:8]:
            t = (it.get("titulo") or it.get("titulo_final") or "").strip()
            r = (it.get("resumo") or it.get("resumo_final") or "").strip()
            pr = (it.get("prioridade") or "").strip()
            tg = (it.get("tag") or "").strip()
            bullets.append(f"- {t} ({pr}{' ¬∑ ' + tg if tg else ''}) ‚Äî {r}")
            for f in it.get("fontes", [])[:2]:
                fid = f.get('id') or it.get('id')
                ft = (f.get('titulo') or t or '').strip()
                url = (f.get('url') or '').strip()
                j = (f.get('jornal') or '').strip()
                if url:
                    fontes_items.append(f"[{fid}] {ft} ‚Äî [{url}]({url}){f' ({j})' if j else ''}")
                else:
                    fontes_items.append(f"[{fid}] {ft}{f' ({j})' if j else ''}")
        md = titulo_secao + "\n" + ("\n".join(bullets) if bullets else "- (sem itens)")
        if fontes_items:
            numeradas = [f"{i}. {txt}" for i, txt in enumerate(fontes_items, start=1)]
            md += "\n\n### Not√≠cias pesquisadas:\n" + "\n".join(numeradas)
        return md

    def _llm_summarize_from_raw(self, question: str, clusters_detalhes: List[Dict[str, Any]]) -> Optional[str]:
        if not self.model or not clusters_detalhes:
            return None
        try:
            # Prepara amostra enxuta de textos brutos
            pacote: List[Dict[str, Any]] = []
            for c in clusters_detalhes[:4]:
                artigos = []
                for a in (c.get("artigos") or [])[:3]:
                    trecho = (a.get("texto_completo") or "")[:1200]
                    artigos.append({
                        "id": a.get("id"),
                        "titulo": a.get("titulo"),
                        "jornal": a.get("jornal"),
                        "url": a.get("url_original"),
                        "trecho": trecho
                    })
                pacote.append({
                    "cluster_id": c.get("id"),
                    "titulo": c.get("titulo_final"),
                    "prioridade": c.get("prioridade"),
                    "tag": c.get("tag"),
                    "artigos": artigos
                })
            instr = (
                "Voc√™ √© analista da mesa de Special Situations do BTG. Escreva um RESUMO em Markdown, direto ao ponto,"
                " usando apenas os textos abaixo (amostra de artigos brutos).\n\n"
                "Regras obrigat√≥rias:\n"
                "- Proibido explicar o plano, ferramentas ou etapas. Responda o que foi pedido.\n"
                "- Estruture com t√≠tulos (##) e bullets.\n"
                "- Conclua com se√ß√£o 'Not√≠cias pesquisadas:' numerada com [ID] T√≠tulo ‚Äî URL (Jornal).\n\n"
                f"Pergunta: {question}\n\n"
                f"Artigos (amostra): {pacote}\n"
            )
            print("[Estagiario] S√≠ntese LLM (raw) iniciada...")
            resp = self.model.generate_content(instr, generation_config={'temperature': 0.2, 'top_p': 0.8, 'max_output_tokens': 896})
            txt = (resp.text or "").strip()
            print(f"[Estagiario] S√≠ntese LLM (raw) conclu√≠da. Len={len(txt)}")
            return txt or None
        except Exception as e:
            print(f"[Estagiario] Falha na s√≠ntese raw: {e}")
            return None

    def _llm_select_candidates(self, question: str, candidates: List[Dict[str, Any]]) -> List[int]:
        """Usa o LLM para triagem sem√¢ntica: escolhe IDs mais relevantes para a pergunta."""
        if not self.model or not candidates:
            return []
        try:
            prio_weight = {"P1_CRITICO": 3, "P2_ESTRATEGICO": 2, "P3_MONITORAMENTO": 1}
            # Prioriza por P1>P2>P3 e limita a 60 itens para n√£o estourar contexto
            ordered = sorted(candidates, key=lambda c: prio_weight.get(c.get("prioridade") or "P3_MONITORAMENTO", 1), reverse=True)
            sample = [
                {
                    "id": c.get("id"),
                    "titulo": c.get("titulo_final") or "",
                    "resumo": c.get("resumo_final") or "",
                    "tag": c.get("tag") or "",
                    "prioridade": c.get("prioridade") or ""
                }
                for c in ordered[:60]
                if c.get("id") is not None
            ]
            instr = (
                "Voc√™ far√° UMA TRIAGEM sem√¢ntica de potenciais oportunidades para a pergunta abaixo.\n"
                "Devolva APENAS um JSON no formato {\"ids\": [<id>, ...]} com os IDs mais relevantes (10‚Äì15).\n"
                "Crit√©rios: prioridade (P1>P2>P3), ader√™ncia tem√°tica, a√ß√£o potencial.\n"
                "N√ÉO explique, N√ÉO use texto fora do JSON.\n\n"
                f"Pergunta: {question}\n\n"
                f"Itens (amostra): {sample}\n"
            )
            print("[Estagiario] Triagem LLM (sele√ß√£o de candidatos) iniciada...")
            resp = self.model.generate_content(instr, generation_config={'temperature': 0.1, 'max_output_tokens': 256})
            txt = (resp.text or "").strip()
            import json, re
            ids: List[int] = []
            try:
                data = json.loads(txt)
                ids = [int(x) for x in data.get("ids", []) if isinstance(x, (int, str))]
            except Exception:
                # Regex de fallback para extrair n√∫meros
                nums = re.findall(r"\d+", txt)
                ids = [int(n) for n in nums[:15]]
            ids = list(dict.fromkeys(ids))  # remove duplicatas mantendo ordem
            print(f"[Estagiario] Triagem LLM selecionou {len(ids)} IDs")
            return ids
        except Exception as e:
            print(f"[Estagiario] Falha na triagem LLM: {e}")
            return []

    def _infer_filters(self, question: str) -> Dict[str, Any]:
        """Inferir prioridades, tags e keywords a partir da pergunta para reduzir o universo."""
        import unicodedata
        def norm(s: str) -> str:
            s = s.lower()
            return ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))
        nq = norm(question)
        # Prioridades
        priorities = []
        if "p1" in nq: priorities.append("P1_CRITICO")
        if "p2" in nq: priorities.append("P2_ESTRATEGICO")
        if "p3" in nq: priorities.append("P3_MONITORAMENTO")
        # Tags heur√≠sticas
        tag_map = {
            "internacional": ["eua", "russia", "r√∫ssia", "china", "guerra", "san\u00e7\u00f5es", "geopolit"],
            "juridico": ["rj", "recuperacao judicial", "judicial", "stj", "stf", "justica"],
            "m&a": ["m&a", "fusao", "fus√£o", "aquisi", "venda de ativo", "desinvest"],
            "mercado_de_capitais": ["ipo", "follow on", "debent", "oferta", "capta\u00e7\u00e3o"],
            "politica_economica": ["congresso", "camara", "senado", "tributar", "fiscal", "arcabou\u00e7o"],
            "tecnologia": ["ia", "tecnolog", "software", "plataforma", "dados"],
            "distressed": ["default", "inadimpl", "calote", "reestrutura", "distressed"],
            "autos": ["carro", "veiculo", "automovel", "montadora", "concessionaria", "ev", "eletrico"],
            "energia": ["energia", "petroleo", "gas", "opec", "opep", "hidrel", "solar", "eolica"],
        }
        tags = set()
        for tag, keys in tag_map.items():
            if any(k in nq for k in keys):
                tags.add(tag)
        # Keywords principais
        tokens = [t for t in nq.split() if len(t) >= 3 and t.isalpha()]
        stops = set(["noticias", "noticia", "todas", "com", "para", "das", "dos", "de", "da", "do", "sobre", "quais", "seriam", "hoje", "mesa", "special", "situations"])
        keywords = [t for t in tokens if t not in stops][:10]
        print(f"[Estagiario] Filtros inferidos ‚Üí priorities={priorities or 'ALL'} tags={list(tags)} keywords={keywords}")
        return {"priorities": priorities, "tags": list(tags), "keywords": keywords}

    def _rank_clusters(self, keywords: List[str], clusters: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        print("[Estagiario] Ranqueando clusters...")
        prio_weight = {"P1_CRITICO": 3, "P2_ESTRATEGICO": 2, "P3_MONITORAMENTO": 1}
        scored = []
        for c in clusters:
            pr = c.get("prioridade") or "P3_MONITORAMENTO"
            base = prio_weight.get(pr, 1)
            blob = ((c.get("titulo_final") or "") + "\n" + (c.get("resumo_final") or "")).lower()
            kw_hits = sum(1 for k in keywords if k in blob)
            score = base * 10 + kw_hits
            scored.append((score, c))
        scored.sort(key=lambda x: x[0], reverse=True)
        ranked = [c for _, c in scored]
        print(f"[Estagiario] Ranking conclu√≠do. total={len(ranked)} top_score={scored[0][0] if scored else 0}")
        return ranked

    def _fetch_details_for(self, db, cluster_ids: List[int], limit: int = 6) -> List[Dict[str, Any]]:
        print(f"[Estagiario] Carregando detalhes para {min(len(cluster_ids), limit)} clusters...")
        detalhes = []
        for cid in cluster_ids[:limit]:
            try:
                d = get_cluster_details_by_id(db, cid)
                if d:
                    detalhes.append(d)
            except Exception as e:
                print(f"[Estagiario] Falha ao carregar detalhes do cluster {cid}: {e}")
        print(f"[Estagiario] Detalhes carregados: {len(detalhes)}")
        return detalhes

    def _count_irrelevantes_clusters(self, db, target_date: datetime.date) -> int:
        """Conta clusters de um dia com prioridade/tag irrelevante (preciso)."""
        try:
            from sqlalchemy import func, and_
            cnt = db.query(func.count(ClusterEvento.id)).filter(
                and_(func.date(ClusterEvento.created_at) == target_date,
                     ClusterEvento.status == 'ativo',
                     ((ClusterEvento.prioridade == 'IRRELEVANTE') | (ClusterEvento.tag == 'IRRELEVANTE')))
            ).scalar() or 0
            print(f"[Estagiario] Irrelevantes (preciso) na data={target_date}: {cnt}")
            return int(cnt)
        except Exception as e:
            print(f"[Estagiario] Falha ao contar irrelevantes precisos: {e}")
            return 0

    def answer(self, question: str, date_str: Optional[str] = None) -> AgentAnswer:
        """
        Responde perguntas com base nas not√≠cias do dia, usando prioridades/tags.
        Exemplos suportados:
        - 1) "liste quantas noticias classificamos como irrelevantes"
        - 2) "quais noticias tem promocoes de carros at√© 200mil?"
        - 3) "Resuma os principais Impactos das noticias de prioridade p1 para a relacao EUA x RUssia"
        """
        print("[Estagiario] ================= IN√çCIO =================")
        print(f"[Estagiario] Pergunta: {question}")
        db = self._open_db()
        try:
            target_date = None
            if date_str:
                try:
                    target_date = datetime.strptime(date_str, "%Y-%m-%d").date()
                except Exception:
                    target_date = get_date_brasil()
            if target_date is None:
                target_date = get_date_brasil()
            print(f"[Estagiario] Data alvo: {target_date.isoformat()}")

            q = (question or "").lower()

            # Executor ReAct (opcional por flag) para casos gen√©ricos
            if os.getenv("ESTAGIARIO_REACT") == "1":
                try:
                    from .executor import EstagiarioExecutor
                    execu = EstagiarioExecutor()
                    out = execu.run(user_input=question, chat_history=[])
                    final = out.get("final") or "Em constru√ß√£o"
                    trace = out.get("trace") or []
                    return AgentAnswer(True, final, {"react_trace": trace})
                except Exception as e:
                    print(f"[Estagiario] Falha executor ReAct: {e}")
                    # cai para heur√≠stica abaixo

            # Caso: comandos de edi√ß√£o (seguros e sempre unit√°rios)
            if q.startswith("atualize ") or q.startswith("troque ") or q.startswith("mude ") or q.startswith("merge ") or q.startswith("unir ") or q.startswith("unifica "):
                print("[Estagiario] Caso: comando de edi√ß√£o")
                import re
                # update prioridade: "atualize prioridade do cluster 123 para p2"
                m = re.search(r"prioridade.*cluster\s+(\d+)\s+para\s+(p1|p2|p3|irrelevante)", q)
                if m:
                    cluster_id = int(m.group(1))
                    alvo = m.group(2).upper()
                    mapa = {"P1": "P1_CRITICO", "P2": "P2_ESTRATEGICO", "P3": "P3_MONITORAMENTO", "IRRELEVANTE": "IRRELEVANTE"}
                    nova_pr = mapa.get(alvo)
                    if nova_pr and nova_pr in self.prioridades_permitidas:
                        from backend.crud import update_cluster_priority
                        ok = update_cluster_priority(db, cluster_id, nova_pr, motivo=f"Estagiario: ajuste solicitado '{question}'")
                        return AgentAnswer(bool(ok), ("‚úÖ Prioridade atualizada." if ok else "Falha ao atualizar prioridade."))
                    return AgentAnswer(False, "Prioridade n√£o permitida.")

                # update tag: "troque a tag do cluster 456 para Internacional"
                m = re.search(r"tag.*cluster\s+(\d+)\s+para\s+([\w√£√°√†√¢√™√≠√ß√µ√©√∫-]+)", q)
                if m:
                    cluster_id = int(m.group(1))
                    tag = m.group(2)
                    # valida contra cat√°logo
                    if any(tag.lower() == t.lower() for t in self.tags_permitidas):
                        from backend.crud import update_cluster_tags
                        ok = update_cluster_tags(db, cluster_id, [tag], motivo=f"Estagiario: ajuste solicitado '{question}'")
                        return AgentAnswer(bool(ok), ("‚úÖ Tag atualizada." if ok else "Falha ao atualizar tag."))
                    return AgentAnswer(False, "Tag n√£o permitida.")

                # merge: "merge o cluster 111 no 222" (sempre unit√°rio; nunca m√∫ltiplos)
                m = re.search(r"merge.*cluster\s+(\d+)\s+no\s+(\d+)", q)
                if m:
                    origem = int(m.group(1))
                    destino = int(m.group(2))
                    if origem == destino:
                        return AgentAnswer(False, "IDs de origem e destino iguais.")
                    from backend.crud import merge_clusters
                    res = merge_clusters(db, destino_id=destino, fontes_ids=[origem], motivo=f"Estagiario: merge solicitado '{question}'")
                    # n√£o reescreve t√≠tulo/tag/prioridade por padr√£o; mant√©m destino como autoridade
                    return AgentAnswer(True, f"‚úÖ Merge efetuado. Artigos movidos: {res.get('artigos_movidos',0)}; Clusters encerrados: {res.get('clusters_descartados',0)}.")

                return AgentAnswer(False, "Comando de edi√ß√£o n√£o reconhecido. Exemplos: 'atualize prioridade do cluster 123 para p2', 'troque a tag do cluster 456 para Internacional', 'merge o cluster 111 no 222'.")

            # Caso 1: contagem de IRRELEVANTES
            if "irrelevante" in q and ("quantas" in q or "liste" in q or "conta" in q):
                print("[Estagiario] Caso: contar irrelevantes")
                irrelevantes = self._count_irrelevantes_clusters(db, target_date)
                print("[Estagiario] Resposta pronta")
                return AgentAnswer(True, f"Irrelevantes hoje: {irrelevantes}")

            # Caso 2: promo√ß√µes de carros (din√¢mico; sem pre√ßo padr√£o)
            if ("carro" in q or "carros" in q) and ("promo" in q or "promo√ß√£o" in q or "promocao" in q or "desconto" in q or "oferta" in q):
                print("[Estagiario] Caso: promo√ß√µes de carros (din√¢mico)")
                import re
                # Extrai pre√ßo alvo se presente (ex.: 200 mil, 200k, 200.000, r$ 200.000)
                preco_alvo = None
                m = re.search(r"r\$\s*([\d\.]+)", q)
                if m:
                    try:
                        preco_alvo = int(m.group(1).replace('.', ''))
                    except Exception:
                        preco_alvo = None
                if not preco_alvo:
                    m = re.search(r"(\d+)\s*mil", q)
                    if m:
                        try:
                            preco_alvo = int(m.group(1)) * 1000
                        except Exception:
                            preco_alvo = None
                if not preco_alvo:
                    m = re.search(r"(\d+)\s*k", q)
                    if m:
                        try:
                            preco_alvo = int(m.group(1)) * 1000
                        except Exception:
                            preco_alvo = None

                candidatos = self._fetch_clusters(db, target_date, priority=None)
                print(f"[Estagiario] Candidatos: {len(candidatos)} pre√ßo_alvo={preco_alvo}")
                achados = []
                termos_base = ["carro", "autom√≥vel", "ve√≠culo", "concession√°ria", "oferta", "desconto", "promo", "ipva", "financiamento"]
                termos_ev = ["el√©trico", "eletrico", "ev", "ve√≠culo el√©trico", "veiculo eletrico"]
                for c in candidatos:
                    t = (c.get("titulo_final") or "").lower()
                    r = (c.get("resumo_final") or "").lower()
                    blob = t + "\n" + r
                    if any(k in blob for k in termos_base):
                        # Se o usu√°rio falou "el√©trico", d√° prefer√™ncia a EV
                        if ("el√©trico" in q or "eletrico" in q) and not any(ev in blob for ev in termos_ev):
                            continue
                        if preco_alvo:
                            # Heur√≠stica: aceitar se houver men√ß√£o num√©rica plaus√≠vel (mil/k/valores pr√≥ximos)
                            if re.search(r"(\d+\.?\d*\s*mil|r\$\s*[\d\.]+|\d+\s*k)", blob):
                                achados.append({"id": c["id"], "titulo": c.get("titulo_final"), "resumo": c.get("resumo_final")})
                        else:
                            achados.append({"id": c["id"], "titulo": c.get("titulo_final"), "resumo": c.get("resumo_final")})
                print(f"[Estagiario] Achados: {len(achados)}")
                if not achados:
                    return AgentAnswer(True, "Nenhuma promo√ß√£o de carros encontrada hoje.")
                llm_txt = self._llm_answer(question, achados)
                if llm_txt:
                    return AgentAnswer(True, llm_txt, {"itens": achados[:10]})
                return AgentAnswer(True, f"{len(achados)} ofertas encontradas.", {"itens": achados[:10]})

            # Caso 3: impactos por prioridade (P1/P2/P3) na rela√ß√£o EUA x R√∫ssia ‚Äî resiliente e multi-strat√©gia
            if ("eua" in q and ("russia" in q or "r√∫ssia" in q)) and ("p1" in q or "prioridade p1" in q or "p2" in q or "prioridade p2" in q or "p3" in q or "prioridade p3" in q):
                prios = []
                if ("p1" in q or "prioridade p1" in q): prios.append("P1_CRITICO")
                if ("p2" in q or "prioridade p2" in q): prios.append("P2_ESTRATEGICO")
                if ("p3" in q or "prioridade p3" in q): prios.append("P3_MONITORAMENTO")
                if not prios:
                    prios = ["P1_CRITICO"]
                print(f"[Estagiario] Caso: impactos {','.join(prios)} EUA‚ÄìR√∫ssia")
                # 1) Coleta por prioridades solicitadas
                candidatos: List[Dict[str, Any]] = []
                for p in prios:
                    lista = self._fetch_clusters(db, target_date, priority=p)
                    print(f"[Estagiario] {p} carregados: {len(lista)}")
                    candidatos.extend(lista)
                # 2) Heur√≠stica l√©xica inicial
                chaves = ["eua", "estados unidos", "washington", "r√∫ssia", "russia", "putin", "kremlin", "nato", "otan", "san√ß√£o", "sancao", "guerra", "ucrania", "ucr√¢nia"]
                relevantes = []
                for c in candidatos:
                    L = ((c.get("titulo_final") or "") + "\n" + (c.get("resumo_final") or "")).lower()
                    if any(k in L for k in chaves):
                        relevantes.append(c)
                print(f"[Estagiario] Relevantes (lexical): {len(relevantes)}")
                # 3) Triagem sem√¢ntica via LLM se ainda pouca ader√™ncia
                base_para_triagem = relevantes if len(relevantes) >= 3 else candidatos
                selecionados_ids = self._llm_select_candidates("Impactos na rela√ß√£o EUA‚ÄìR√∫ssia", base_para_triagem)
                if selecionados_ids:
                    idset = set(selecionados_ids)
                    selecionados = [c for c in base_para_triagem if c.get("id") in idset]
                else:
                    selecionados = relevantes[:12] if relevantes else candidatos[:12]
                print(f"[Estagiario] Selecionados p/ s√≠ntese: {len(selecionados)}")
                if not selecionados:
                    return AgentAnswer(True, "Nenhum impacto relevante encontrado nas prioridades solicitadas.")
                # 4) Detalhes + s√≠ntese (resumos) ‚Üí fallback raw
                top_ids = [c.get("id") for c in selecionados[:10] if c.get("id") is not None]
                detalhes = self._fetch_details_for(db, top_ids, limit=6)
                retrieved = []
                for d in detalhes:
                    retrieved.append({
                        "id": d.get("id"),
                        "titulo": d.get("titulo_final") or d.get("titulo_cluster") or d.get("titulo"),
                        "resumo": d.get("resumo_final") or d.get("resumo_cluster") or d.get("resumo"),
                        "tag": d.get("tag"),
                        "prioridade": d.get("prioridade"),
                        "fontes": d.get("fontes", []),
                    })
                llm_txt = self._llm_answer(question, retrieved if retrieved else selecionados)
                if llm_txt and len(llm_txt) > 80:
                    return AgentAnswer(True, llm_txt, {"itens": selecionados[:12]})
                if detalhes:
                    raw_txt = self._llm_summarize_from_raw(question, detalhes)
                    if raw_txt and len(raw_txt) > 80:
                        return AgentAnswer(True, raw_txt, {"itens": selecionados[:12]})
                # 5) Amostra em Markdown
                simples = []
                for c in selecionados[:8]:
                    simples.append({
                        "id": c.get('id'),
                        "titulo": c.get('titulo_final'),
                        "resumo": c.get('resumo_final'),
                        "prioridade": c.get('prioridade'),
                        "tag": c.get('tag'),
                        "fontes": []
                    })
                md = self._compose_markdown_from_retrieved(question, simples)
                return AgentAnswer(True, md, {"itens": selecionados[:12]})

            # Caso 4: busca gen√©rica com plano (inferir filtros ‚Üí filtrar ‚Üí ranquear ‚Üí aprofundar ‚Üí s√≠ntese Markdown)
            try:
                print("[Estagiario] Caso: busca gen√©rica por palavras-chave (com plano)")
                filtros = self._infer_filters(q)
                # Coleta priorizada por prioridades inferidas ou ALL
                candidatos: List[Dict[str, Any]] = []
                if filtros["priorities"]:
                    for p in filtros["priorities"]:
                        candidatos.extend(self._fetch_clusters(db, target_date, priority=p))
                else:
                    candidatos = self._fetch_clusters(db, target_date, priority=None)
                print(f"[Estagiario] Candidatos (pr√©-tag): {len(candidatos)}")
                # Filtra por tags inferidas (se houver)
                if filtros["tags"]:
                    candidatos = [c for c in candidatos if any(tg in (c.get("tag") or '').lower() for tg in filtros["tags"]) ]
                print(f"[Estagiario] Ap√≥s filtro de tags: {len(candidatos)}")
                # Opcional: filtragem leve por keyword (evita perder muito recall)
                if filtros["keywords"] and len(candidatos) > 160:
                    def contains_kw(c):
                        L = ((c.get("titulo_final") or "") + "\n" + (c.get("resumo_final") or "")).lower()
                        return any(k in L for k in filtros["keywords"])
                    candidatos = [c for c in candidatos if contains_kw(c)]
                    print(f"[Estagiario] Ap√≥s filtro leve de keywords: {len(candidatos)}")
                if not candidatos:
                    raise ValueError("Nenhum candidato ap√≥s filtros")
                # Triagem sem√¢ntica via LLM para escolher 10-15 mais promissores
                selected_ids = self._llm_select_candidates(question, candidatos)
                # Se falhar, usa ranking por prioridade/keywords
                if not selected_ids:
                    ranked = self._rank_clusters(filtros["keywords"], candidatos)
                    top_ids = [c.get("id") for c in ranked[:12] if c.get("id") is not None]
                else:
                    top_ids = selected_ids[:12]
                detalhes = self._fetch_details_for(db, top_ids, limit=8)
                # Monta retrieved enriquecido com fontes
                retrieved: List[Dict[str, Any]] = []
                for d in detalhes:
                    retrieved.append({
                        "id": d.get("id"),
                        "titulo": d.get("titulo_final") or d.get("titulo_cluster") or d.get("titulo"),
                        "resumo": d.get("resumo_final") or d.get("resumo_cluster") or d.get("resumo"),
                        "tag": d.get("tag"),
                        "prioridade": d.get("prioridade"),
                        "fontes": d.get("fontes", []),
                        "artigos": d.get("artigos", []),
                    })
                # S√≠ntese LLM em Markdown
                base_para_sintese = retrieved if retrieved else [c for c in candidatos if (c.get("id") in top_ids)][:10]
                llm_txt = self._llm_answer(question, base_para_sintese)
                if llm_txt and len(llm_txt) > 500:
                    return AgentAnswer(True, llm_txt, {"itens": base_para_sintese[:15]})
                # Se a s√≠ntese acima falhar, tenta construir resumo a partir dos artigos brutos
                if detalhes:
                    raw_txt = self._llm_summarize_from_raw(question, detalhes)
                    if raw_txt:
                        return AgentAnswer(True, raw_txt, {"itens": base_para_sintese[:15]})
                # Fallback em Markdown simples com rastreabilidade
                id_set = set(top_ids)
                simples = [
                    {
                        "id": c.get('id'),
                        "titulo": c.get('titulo_final'),
                        "resumo": c.get('resumo_final'),
                        "prioridade": c.get('prioridade'),
                        "tag": c.get('tag'),
                        "fontes": [],
                        "artigos": [],
                    }
                    for c in candidatos if c.get('id') in id_set
                ][:8]
                md = self._compose_markdown_from_retrieved(question, simples)
                return AgentAnswer(True, md, {"itens": simples[:15]})
            except Exception as _e_generic:
                print(f"[Estagiario] Falha na busca gen√©rica: {_e_generic}")

            # Fallback: responde com m√©tricas gerais do dia
            print("[Estagiario] Fallback: m√©tricas do dia")
            metricas = get_metricas_by_date(db, target_date)
            print(f"[Estagiario] M√©tricas: {metricas}")
            return AgentAnswer(True, "Em constru√ß√£o üöß ‚Äî Fa√ßa uma pergunta espec√≠fica.", {"metricas": metricas})

        except Exception as e:
            print(f"[Estagiario] ERRO: {e}")
            return AgentAnswer(False, f"Falha no agente: {e}")
        finally:
            try:
                print("[Estagiario] Fechando sess√£o DB...")
                db.close()
            except Exception:
                pass
            print("[Estagiario] =================  FIM  =================")


